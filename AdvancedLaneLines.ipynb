{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Lane Finding Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "---\n",
    "## Compute the camera calibration using chessboard images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def get_calibration_parameters():\n",
    "    \"\"\"\n",
    "    get parameters for camera calibration from chessboard images\n",
    "    \"\"\"\n",
    "    # prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "    objp = np.zeros((6*9,3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "    \n",
    "    # Arrays to store object points and image points from all the images.\n",
    "    objpoints = [] # 3d points in real world space\n",
    "    imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "    # Make a list of calibration images\n",
    "    images = glob.glob('camera_cal/calibration*.jpg')\n",
    "\n",
    "    # Step through the list and search for chessboard corners\n",
    "    for fname in images:\n",
    "        img = cv2.imread(fname)\n",
    "        gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Find the chessboard corners\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (9,6), None)\n",
    "\n",
    "        # If found, add object points, image points\n",
    "        if ret == True:\n",
    "            objpoints.append(objp)\n",
    "            imgpoints.append(corners)\n",
    "    \n",
    "    return objpoints, imgpoints    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply a distortion correction to raw images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_undistorted_image(image, objpoints, imgpoints):\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, image.shape[0:2], None, None)\n",
    "    return cv2.undistort(image, mtx, dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_processed_images(original, processed):\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 6))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(original)\n",
    "    ax1.set_title('Original Image', fontsize=15)\n",
    "    ax2.imshow(processed, cmap='gray')\n",
    "    ax2.set_title('Processed Image', fontsize=15)\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"camera_cal/calibration1.jpg\")\n",
    "objpoints, imgpoints = get_calibration_parameters()\n",
    "undistorted = get_undistorted_image(image, objpoints, imgpoints)\n",
    "show_processed_images(image, undistorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Create a thresholded binary image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_color_threshold_binary_image(image,  thresh=(150, 250)):\n",
    "    hls = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "    s_channel = hls[:,:,2]\n",
    "    \n",
    "    binary_output = np.zeros_like(s_channel)\n",
    "    binary_output[(s_channel >= thresh[0]) & (s_channel <= thresh[1])] = 1\n",
    "    return binary_output\n",
    "\n",
    "\n",
    "def get_absolute_sobel_threshold_binary_image(image, orient='x', thresh=(20, 100)):\n",
    "    gray = cv2.cvtColor(image.copy(), cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    if orient == 'x':\n",
    "        sobel = cv2.Sobel(gray, cv2.CV_64F, 1, 0)\n",
    "    if orient == 'y':\n",
    "        sobel = cv2.Sobel(gray, cv2.CV_64F, 0, 1)\n",
    "        \n",
    "    abs_sobel = np.absolute(sobel)\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "\n",
    "    binary_output = np.zeros_like(scaled_sobel)\n",
    "    binary_output[(scaled_sobel >= thresh[0]) & (scaled_sobel <= thresh[1])] = 1\n",
    "    return binary_output\n",
    "\n",
    "    \n",
    "def get_magnitude_threshold_binary_image(image, sobel_kernel=3, thresh=(30, 100)):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    \n",
    "    gradmag = np.sqrt(sobelx**2 + sobely**2)\n",
    "\n",
    "    scaled_sobel = np.uint8(255*gradmag/np.max(gradmag))\n",
    "\n",
    "    binary_output = np.zeros_like(scaled_sobel)\n",
    "    binary_output[(scaled_sobel >= thresh[0]) & (scaled_sobel <= thresh[1])] = 1\n",
    "    return binary_output\n",
    "\n",
    "\n",
    "def get_dicrection_threshold_binary_image(image, sobel_kernel=15, thresh=(0.7, 1.3)):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    \n",
    "    abs_sobelx = np.absolute(sobelx)\n",
    "    abs_sobely = np.absolute(sobely)\n",
    "    \n",
    "    gradmag = np.arctan2(abs_sobely, abs_sobelx)\n",
    "    \n",
    "    binary_output = np.zeros_like(gradmag)\n",
    "    binary_output[(gradmag >= thresh[0]) & (gradmag <= thresh[1])] = 1\n",
    "    return binary_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_binary_image(image):\n",
    "    \"\"\"\n",
    "    Create thresholded binary image using color and gradient\n",
    "    \"\"\"\n",
    "    color_th_binary = get_color_threshold_binary_image(image, thresh=(150, 250))\n",
    "    mag_th_binary = get_magnitude_threshold_binary_image(image, sobel_kernel=7, thresh=(50, 250))\n",
    "    abs_sobel_th_binary = get_absolute_sobel_threshold_binary_image(image, thresh=(30, 100))\n",
    "    #dic_th_binary = get_dicrection_threshold_binary_image(image)\n",
    "\n",
    "    binary_image = np.zeros_like(color_th_binary)\n",
    "    #binary_image[(color_th_binary == 1) | (mag_th_binary == 1) | (dic_th_binary == 1)] = 1\n",
    "    #binary_image[(color_th_binary == 1) | (mag_th_binary == 1) | (abs_sobel_th_binary == 1)] = 1\n",
    "    binary_image[(color_th_binary == 1) | (mag_th_binary == 1) | (abs_sobel_th_binary == 1)] = 1\n",
    "\n",
    "    return binary_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#  visualize result of get_color_threshold_binary_image using some parameter\n",
    "max_ths = [200, 250, 255]\n",
    "min_ths = [100, 120, 140, 160, 170]\n",
    "\n",
    "i = 0\n",
    "plt.figure(figsize=(25,10))\n",
    "for max_th  in max_ths:\n",
    "    for min_th in min_ths:\n",
    "        plt.subplot(3, 5, i+1)\n",
    "        train_image = get_color_threshold_binary_image(image, thresh=(min_th, max_th))\n",
    "        plt.imshow(train_image, cmap='gray')\n",
    "        title = \"th_min:{}, th_max:{}\".format(min_th, max_th)\n",
    "        plt.title(title)\n",
    "        i += 1\n",
    "\n",
    "#plt.savefig(\"color_some_params_2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#  visualize result of get_absolute_sobel_threshold_binary_image using some parameter\n",
    "image = mpimg.imread('test_images/test1.jpg')\n",
    "\n",
    "max_ths = [100, 150, 200, 250, 255]\n",
    "min_ths = [10, 20, 40, 50, 70]\n",
    "\n",
    "i = 0\n",
    "plt.figure(figsize=(25,20))\n",
    "for max_th  in max_ths:\n",
    "    for min_th in min_ths:\n",
    "        plt.subplot(5, 5, i+1)\n",
    "        train_image = get_absolute_sobel_threshold_binary_image(image, thresh=(min_th, max_th))\n",
    "        plt.imshow(train_image, cmap='gray')\n",
    "        title = \"th_min:{}, th_max:{}\".format(min_th, max_th)\n",
    "        plt.title(title)\n",
    "        i += 1\n",
    "\n",
    "#plt.savefig(\"abs_sobel_some_params_test1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#  visualize result of get_magnitude_threshold_binary_image using some parameter\n",
    "max_ths = [100, 150, 200, 250, 255]\n",
    "min_ths = [20, 40, 50, 70]\n",
    "\n",
    "i = 0\n",
    "plt.figure(figsize=(25,20))\n",
    "for max_th  in max_ths:\n",
    "    for min_th in min_ths:\n",
    "        plt.subplot(5, 4, i+1)\n",
    "        train_image = get_magnitude_threshold_binary_image(image, sobel_kernel=3, thresh=(min_th, max_th))\n",
    "        plt.imshow(train_image, cmap='gray')\n",
    "        title = \"th_min:{}, th_max:{}\".format(min_th, max_th)\n",
    "        plt.title(title)\n",
    "        i += 1\n",
    "\n",
    "#plt.savefig(\"magnitude_some_params_k3.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply a perspective transform to rectify binary image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_warped_area_image(image):\n",
    "    imshape = image.shape\n",
    "\n",
    "    margin = 200\n",
    "    vertices = np.array([[(margin, imshape[0]),(600, 450), (680, 450), (imshape[1]-margin, imshape[0])]], dtype=np.int32)\n",
    "\n",
    "    plotted_image = cv2.polylines(image.copy(), vertices, 1, 255, thickness=3)\n",
    "    #plt.imshow(plotted_image)\n",
    "    return plotted_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_perspective_transformed_image(image, inv=0):\n",
    "    imshape = image.shape\n",
    "    lr_margin = 200\n",
    "    tb_margin = 30\n",
    "    dst_margin = 350\n",
    "    \n",
    "    target = np.float32([[(lr_margin, imshape[0]-tb_margin),(600, 450), (680, 450), (imshape[1]-lr_margin, imshape[0]-tb_margin)]])\n",
    "    destination = np.float32([[dst_margin, imshape[0]], [dst_margin, 0], [imshape[1] - dst_margin, 0], [imshape[1] - 300, imshape[0]]])\n",
    "    M = cv2.getPerspectiveTransform(target, destination)\n",
    "    \n",
    "    if inv == 0:\n",
    "        transformed = cv2.warpPerspective(image, M, (imshape[1],  imshape[0]))\n",
    "    elif inv == 1:\n",
    "        transformed = cv2.warpPerspective(image, M, (imshape[1],  imshape[0]), flags=cv2.WARP_INVERSE_MAP)\n",
    "   \n",
    "    return transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# visualizing preprocessed images\n",
    "# Binalize -> Perspective transform\n",
    "\n",
    "image_list = glob.glob('test_images/*.jpg')\n",
    "\n",
    "for fname in image_list:\n",
    "    image = mpimg.imread(fname)\n",
    "    plotted = get_warped_area_image(image)\n",
    "    processed = get_binary_image(image)\n",
    "    warped = get_perspective_transformed_image(processed)\n",
    "\n",
    "    #warped = get_perspective_transformed_image(image)\n",
    "    #processed = get_binary_image(image)\n",
    "\n",
    "    f, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(20, 12))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(image)\n",
    "    ax1.set_title('Original Image', fontsize=10)\n",
    "    ax2.imshow(plotted)\n",
    "    ax2.set_title('Warped Area', fontsize=10)\n",
    "    ax3.imshow(processed, cmap='gray')\n",
    "    ax3.set_title('Binarized Image', fontsize=10)\n",
    "    ax4.imshow(warped, cmap='gray')\n",
    "    ax4.set_title('Warped Image', fontsize=10)\n",
    "    \n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "    \n",
    "    output_name = 'pre2_' + fname.split('/')[-1]\n",
    "   # plt.savefig(output_name, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# visualizing preprocessed images,\n",
    "# Perspective transform -> Binalize\n",
    "image_list = glob.glob('test_images/*.jpg')\n",
    "\n",
    "for fname in image_list:\n",
    "    image = mpimg.imread(fname)\n",
    "    plotted = get_warped_area_image(image)\n",
    "    warped = get_perspective_transformed_image(image)\n",
    "    processed = get_binary_image(warped)\n",
    "\n",
    "\n",
    "    f, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(1, 5, figsize=(30, 18))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(image)\n",
    "    ax1.set_title('Original Image', fontsize=10)\n",
    "    ax2.imshow(plotted)\n",
    "    ax2.set_title('Warped Area', fontsize=10)\n",
    "    ax3.imshow(warped)\n",
    "    ax3.set_title('Warped Image', fontsize=10)\n",
    "    ax4.imshow(processed, cmap='gray')\n",
    "    ax4.set_title('Binarized Image', fontsize=10)\n",
    "    \n",
    "    # Remove side of warped iamge to prevent misrecognition\n",
    "    processed[:, 0:180] = 0\n",
    "    processed[:, 1100:1280] = 0\n",
    "    ax5.imshow(processed, cmap='gray')\n",
    "    ax5.set_title('Binarized Image removed noise', fontsize=10)\n",
    "    \n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "    \n",
    "    output_name = 'pre2_' + fname.split('/')[-1]\n",
    "   # plt.savefig(output_name, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get target image\n",
    "image = mpimg.imread('test_images/test2.jpg')\n",
    "warped = get_perspective_transformed_image(image)\n",
    "target_image = get_binary_image(warped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect lane pixels and fit to find the lane boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import AdvLaneLine\n",
    "import importlib\n",
    "\n",
    "importlib.reload(AdvLaneLine)\n",
    "getLL = AdvLaneLine.getLaneLine()\n",
    "getLL.sliding_window_search(target_image)\n",
    "plotted = getLL.get_plotted_lane_lines_binalized_image(target_image)\n",
    "plt.imshow(plotted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine the curvature of the lane and vehicle position with respect to center."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "left_curve, right_curve = getLL.determine_curvature(target_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"left_curve:{}, right_curve:{}\".format(left_curve, right_curve)) #test1.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "v_position = getLL.get_vehicle_position()\n",
    "print(v_position)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warp the detected lane boundaries back onto the original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invimg = get_perspective_transformed_image(plotted, inv=1)\n",
    "show_processed_images(plotted, invimg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = cv2.addWeighted(image, 1, invimg, 1, 0)\n",
    "plt.imshow(ans)\n",
    "#plt.savefig(\"test1.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on Video\n",
    "Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datetime import datetime\n",
    "import AdvLaneLine\n",
    "import importlib\n",
    "importlib.reload(AdvLaneLine)\n",
    "\n",
    "objpoints, imgpoints = get_calibration_parameters()\n",
    "AdvLL = AdvLaneLine.getLaneLine()\n",
    "\n",
    "def pipeline(image, objpoints=objpoints, imgpoints=imgpoints, AdvLaneLine=AdvLaneLine):\n",
    "    undistorted = get_undistorted_image(image, objpoints, imgpoints)\n",
    "    warped = get_perspective_transformed_image(undistorted)\n",
    "    binarized = get_binary_image(warped)\n",
    "    \n",
    "    # Remove side of warped iamge to prevent misrecognition\n",
    "    binarized[:, 0:180] = 0\n",
    "    binarized[:, 1100:1280] = 0\n",
    "    \n",
    "    AdvLL.sliding_window_search(binarized)\n",
    "    detected = AdvLL.get_plotted_lane_lines_binalized_image(binarized)\n",
    "    \n",
    "    left_curve, right_curve = AdvLL.determine_curvature(detected)\n",
    "    vehicle_position = AdvLL.get_vehicle_position()\n",
    "    \n",
    "    # Warp the detected lane boundaries back onto the original image\n",
    "    unwarped = get_perspective_transformed_image(detected, inv=1)\n",
    "    result = cv2.addWeighted(image, 1, unwarped, 1, 0)\n",
    "\n",
    "    left_cuv_text = \"Radius of curvature at left = {:.2f}(m)\".format(left_curve)\n",
    "    right_cuv_text = \"Radius of curvature at right = {:.2f}(m)\".format(right_curve)\n",
    "   \n",
    "    if vehicle_position >= 0:\n",
    "        vehicle_position_text = \"Vehicle is {:.2f}m left of center\".format(abs(vehicle_position))\n",
    "    else:\n",
    "        vehicle_position_text = \"Vehicle is {:.2f}m right of center\".format(abs(vehicle_position))\n",
    "    \n",
    "    cv2.putText(result, left_cuv_text, (20,50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255),3, cv2.LINE_AA)\n",
    "    cv2.putText(result, right_cuv_text, (20,100), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255),3, cv2.LINE_AA)\n",
    "    cv2.putText(result, vehicle_position_text, (20,150), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255),3, cv2.LINE_AA)\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    f, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(20, 12))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(image)\n",
    "    ax1.set_title('Original Image', fontsize=10)\n",
    "    ax2.imshow(warped)\n",
    "    ax2.set_title('Warped Image', fontsize=10)\n",
    "    ax3.imshow(binarized, cmap='gray')\n",
    "    ax3.set_title('Binarized Image', fontsize=10)\n",
    "    ax4.imshow(result, cmap='gray')\n",
    "    ax4.set_title('Detect Lane Lines', fontsize=10)\n",
    "    \n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "    \n",
    "    #plt.imshow(result)\n",
    "    plt.savefig(\"output_images/result3/result_{}.png\".format(datetime.now().isoformat()), bbox_inches=\"tight\")\n",
    "    \"\"\"\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "white_output = 'result_mini_test_right_2.mp4'\n",
    "clip1 = VideoFileClip('mini_test_samples/mini_test_right.mp4')\n",
    "white_clip = clip1.fl_image(pipeline)\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SDCpy35",
   "language": "python",
   "name": "sdcpy35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
