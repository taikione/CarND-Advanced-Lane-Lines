{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Lane Finding Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "---\n",
    "## Compute the camera calibration using chessboard images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def get_calibration_parameters():\n",
    "    \"\"\"\n",
    "    get parameters for camera calibration from chessboard images\n",
    "    \"\"\"\n",
    "    # prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "    objp = np.zeros((6*9,3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "    \n",
    "    # Arrays to store object points and image points from all the images.\n",
    "    objpoints = [] # 3d points in real world space\n",
    "    imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "    # Make a list of calibration images\n",
    "    images = glob.glob('camera_cal/calibration*.jpg')\n",
    "\n",
    "    # Step through the list and search for chessboard corners\n",
    "    for fname in images:\n",
    "        img = cv2.imread(fname)\n",
    "        gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Find the chessboard corners\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (9,6), None)\n",
    "\n",
    "        # If found, add object points, image points\n",
    "        if ret == True:\n",
    "            objpoints.append(objp)\n",
    "            imgpoints.append(corners)\n",
    "    \n",
    "    return objpoints, imgpoints    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply a distortion correction to raw images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_undistorted_image(image, objpoints, imgpoints):\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, image.shape[0:2], None, None)\n",
    "    return cv2.undistort(image, mtx, dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_processed_images(original, processed):\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 6))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(original)\n",
    "    ax1.set_title('Original Image', fontsize=15)\n",
    "    ax2.imshow(processed, cmap='gray')\n",
    "    ax2.set_title('Processed Image', fontsize=15)\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"camera_cal/calibration1.jpg\")\n",
    "objpoints, imgpoints = get_calibration_parameters()\n",
    "undistorted = get_undistorted_image(image, objpoints, imgpoints)\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 6))\n",
    "f.tight_layout()\n",
    "ax1.imshow(image)\n",
    "ax1.set_title('Original Image', fontsize=15)\n",
    "ax2.imshow(undistorted, cmap='gray')\n",
    "ax2.set_title('Undistorted Image', fontsize=15)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "plt.savefig(\"images/undistorted_board.png\",bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = mpimg.imread(\"test_images/test5.jpg\")\n",
    "objpoints, imgpoints = get_calibration_parameters()\n",
    "undistorted = get_undistorted_image(image, objpoints, imgpoints)\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 6))\n",
    "f.tight_layout()\n",
    "ax1.imshow(image)\n",
    "ax1.set_title('Original Image', fontsize=15)\n",
    "ax2.imshow(undistorted)\n",
    "ax2.set_title('Undistorted Image', fontsize=15)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "plt.savefig(\"images/undistorted.png\",bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply a perspective transform to raw image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_warped_area_image(image):\n",
    "    imshape = image.shape\n",
    "    \n",
    "    lr_margin = 300\n",
    "    tb_margin = 30\n",
    "    vertices = np.array([[(lr_margin, imshape[0]-tb_margin),(600, 450), (680, 450), (imshape[1]-lr_margin, imshape[0]-tb_margin)]], dtype=np.int32)\n",
    "\n",
    "    plotted_image = cv2.polylines(image.copy(), vertices, 1, 255, thickness=3)\n",
    "    #plt.imshow(plotted_image)\n",
    "    return plotted_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_perspective_transformed_image(image, inv=0, plot=0):\n",
    "    imshape = image.shape\n",
    "    lr_margin = 300 # left and right margin\n",
    "    tb_margin = 30 # top and bottom margin\n",
    "    dst_margin = 350 # destination \n",
    "    \n",
    "    source = np.float32([[(lr_margin, imshape[0]-tb_margin),(600, 450), (680, 450), (imshape[1]-lr_margin, imshape[0]-tb_margin)]])\n",
    "    destination = np.float32([[dst_margin, imshape[0]], [dst_margin, 0], [imshape[1] - dst_margin, 0], [imshape[1] - dst_margin, imshape[0]]])\n",
    "    M = cv2.getPerspectiveTransform(source, destination)\n",
    "    \n",
    "    if inv == 0:\n",
    "        transformed = cv2.warpPerspective(image, M, (imshape[1],  imshape[0]))\n",
    "    elif inv == 1:\n",
    "        transformed = cv2.warpPerspective(image, M, (imshape[1],  imshape[0]), flags=cv2.WARP_INVERSE_MAP)\n",
    "   \n",
    "    if plot == 1:\n",
    "        warped_vertices = np.array([[(dst_margin, imshape[0]), (dst_margin, 0), (imshape[1] - dst_margin, 0), (imshape[1] - dst_margin, imshape[0])]], dtype=np.int32)   \n",
    "        transformed = cv2.polylines(transformed.copy(), warped_vertices, 1, 255, thickness=3)\n",
    "\n",
    "    return transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verified perspective transform\n",
    "plotted = get_warped_area_image(undistorted)\n",
    "warped = get_perspective_transformed_image(undistorted, plot=1)\n",
    "\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 6))\n",
    "f.tight_layout()\n",
    "ax1.imshow(plotted)\n",
    "ax1.set_title('Undistorted Image with source points drawn', fontsize=15)\n",
    "ax2.imshow(warped)\n",
    "ax2.set_title('Warped image', fontsize=15)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "plt.savefig(\"images/warped.png\",bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a thresholded binary image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_color_threshold_binary_image(image,  thresh=(150, 250)):\n",
    "    hls = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "    s_channel = hls[:,:,2]\n",
    "    \n",
    "    binary_output = np.zeros_like(s_channel)\n",
    "    binary_output[(s_channel >= thresh[0]) & (s_channel <= thresh[1])] = 1\n",
    "    return binary_output\n",
    "\n",
    "\n",
    "def get_absolute_sobel_threshold_binary_image(image, orient='x', thresh=(20, 100)):\n",
    "    gray = cv2.cvtColor(image.copy(), cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    if orient == 'x':\n",
    "        sobel = cv2.Sobel(gray, cv2.CV_64F, 1, 0)\n",
    "    if orient == 'y':\n",
    "        sobel = cv2.Sobel(gray, cv2.CV_64F, 0, 1)\n",
    "        \n",
    "    abs_sobel = np.absolute(sobel)\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "\n",
    "    binary_output = np.zeros_like(scaled_sobel)\n",
    "    binary_output[(scaled_sobel >= thresh[0]) & (scaled_sobel <= thresh[1])] = 1\n",
    "    return binary_output\n",
    "\n",
    "    \n",
    "def get_magnitude_threshold_binary_image(image, sobel_kernel=3, thresh=(30, 100)):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    \n",
    "    gradmag = np.sqrt(sobelx**2 + sobely**2)\n",
    "\n",
    "    scaled_sobel = np.uint8(255*gradmag/np.max(gradmag))\n",
    "\n",
    "    binary_output = np.zeros_like(scaled_sobel)\n",
    "    binary_output[(scaled_sobel >= thresh[0]) & (scaled_sobel <= thresh[1])] = 1\n",
    "    return binary_output\n",
    "\n",
    "\n",
    "def get_dicrection_threshold_binary_image(image, sobel_kernel=15, thresh=(0.7, 1.3)):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    \n",
    "    abs_sobelx = np.absolute(sobelx)\n",
    "    abs_sobely = np.absolute(sobely)\n",
    "    \n",
    "    gradmag = np.arctan2(abs_sobely, abs_sobelx)\n",
    "    \n",
    "    binary_output = np.zeros_like(gradmag)\n",
    "    binary_output[(gradmag >= thresh[0]) & (gradmag <= thresh[1])] = 1\n",
    "\n",
    "    return binary_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_binary_image(image):\n",
    "    \"\"\"\n",
    "    Create thresholded binary image using color and gradient\n",
    "    \"\"\"\n",
    "    color_th_binary = get_color_threshold_binary_image(image, thresh=(120, 255))\n",
    "    mag_th_binary = get_magnitude_threshold_binary_image(image, sobel_kernel=7, thresh=(20, 255))\n",
    "    abs_sobel_x_th_binary = get_absolute_sobel_threshold_binary_image(image, orient='x', thresh=(30, 100))\n",
    "    abs_sobel_y_th_binary = get_absolute_sobel_threshold_binary_image(image, orient='y', thresh=(30, 100))\n",
    "\n",
    "    #dic_th_binary = get_dicrection_threshold_binary_image(image,sobel_kernel=31, thresh=(50*np.pi/180, 60*np.pi/180))\n",
    "\n",
    "    binary_image = np.zeros_like(color_th_binary)\n",
    "    #binary_image[(color_th_binary == 1) | (mag_th_binary == 1) | (dic_th_binary == 1)] = 1\n",
    "    binary_image[(color_th_binary == 1) | (mag_th_binary == 1) | (abs_sobel_x_th_binary == 1)] = 1\n",
    "    #binary_image[(color_th_binary == 1) | (mag_th_binary == 1) | (abs_sobel_th_binary == 1) | (dic_th_binary)] = 1\n",
    "    binary_image[(abs_sobel_y_th_binary == 1)] = 0\n",
    "\n",
    "    return binary_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binarize\n",
    "warped = get_perspective_transformed_image(undistorted)\n",
    "processed = get_binary_image(warped)\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 6))\n",
    "f.tight_layout()\n",
    "ax1.imshow(warped)\n",
    "ax1.set_title('Warped image', fontsize=15)\n",
    "ax2.imshow(processed, cmap='gray')\n",
    "ax2.set_title('Binarized image', fontsize=15)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "plt.savefig(\"images/binarize.png\",bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Shadow detection and removal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A robust approach for road detection with shadow removal technique\n",
    "def get_removed_shadow_binary_image(image, th=0.7):\n",
    "    hsv = cv2.cvtColor(image.copy(), cv2.COLOR_RGB2HSV)\n",
    "    h = hsv[:,:,0]\n",
    "    v = hsv[:,:,2]\n",
    "    \n",
    "    gray = cv2.cvtColor(image.copy(), cv2.COLOR_RGB2GRAY)\n",
    "    ratio_image = np.zeros_like(gray)\n",
    "    ratio_image[(gray >= ( h.mean()*th+1 / v.mean()*th+1 ))] = 1\n",
    "\n",
    "    ret, shadow = cv2.threshold(ratio_image, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    \n",
    "    return shadow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warped = get_perspective_transformed_image(undistorted)\n",
    "processed = get_binary_image(warped)\n",
    "\n",
    "hsv = cv2.cvtColor(warped.copy(), cv2.COLOR_RGB2HSV)\n",
    "h = hsv[:,:,0]\n",
    "v = hsv[:,:,2]\n",
    "th = 0.7\n",
    "\n",
    "gray = cv2.cvtColor(warped.copy(), cv2.COLOR_RGB2GRAY)\n",
    "ratio_image = np.zeros_like(gray)\n",
    "ratio_image[(gray >= ( h.mean()*th+1 / v.mean()*th+1 ))] = 1\n",
    "\n",
    "ret, shadow = cv2.threshold(ratio_image, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "\n",
    "f, (ax0, ax1, ax2 , ax3) = plt.subplots(1, 4, figsize=(10, 6))\n",
    "f.tight_layout()\n",
    "ax0.imshow(warped)\n",
    "ax0.set_title('Warped Image', fontsize=10)\n",
    "\n",
    "ax1.imshow(processed, cmap='gray')\n",
    "ax1.set_title('Binarize Image', fontsize=10)\n",
    "ax2.imshow(shadow, cmap='gray')\n",
    "ax2.set_title('Detect shadow', fontsize=10)\n",
    "\n",
    "processed[(shadow == 0)] = 0\n",
    "ax3.imshow(processed, cmap='gray')\n",
    "ax3.set_title('Remove Shadow', fontsize=10)\n",
    "\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "plt.savefig(\"images/shadow_detect.png\",bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Varify all preprocessing before window search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# visualizing preprocessed images,\n",
    "# Perspective transform -> Binalize\n",
    "image_list = glob.glob('test_images/*.jpg')\n",
    "\n",
    "for fname in image_list:\n",
    "    image = mpimg.imread(fname)\n",
    "    plotted = get_warped_area_image(image)\n",
    "    warped = get_perspective_transformed_image(image)\n",
    "    processed = get_binary_image(warped)\n",
    "    shadow = get_removed_shadow_binary_image(warped)\n",
    "\n",
    "    f, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(1, 5, figsize=(30, 18))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(image)\n",
    "    ax1.set_title('Original Image', fontsize=10)\n",
    "    ax2.imshow(plotted)\n",
    "    ax2.set_title('Warped Area', fontsize=10)\n",
    "    ax3.imshow(warped)\n",
    "    ax3.set_title('Warped Image', fontsize=10)\n",
    "    ax4.imshow(processed, cmap='gray')\n",
    "    ax4.set_title('Binarized Image', fontsize=10)\n",
    "    \n",
    "    processed[(shadow == 0)] = 0\n",
    "    ax5.imshow(processed, cmap='gray')\n",
    "    ax5.set_title('Remove Shadow', fontsize=10)\n",
    "    \n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "    \n",
    "    output_name = 'fix_' + fname.split('/')[-1]\n",
    "    #plt.savefig(output_name, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect lane pixels and fit to find the lane boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import AdvLaneLine\n",
    "import importlib\n",
    "\n",
    "importlib.reload(AdvLaneLine)\n",
    "\n",
    "getLL = AdvLaneLine.getLaneLine()\n",
    "getLL.sliding_window_search(processed)\n",
    "plotted = getLL.get_plotted_lane_lines_binalized_image(processed)\n",
    "\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 6))\n",
    "f.tight_layout()\n",
    "ax1.imshow(processed, cmap='gray')\n",
    "ax1.set_title('Warped image', fontsize=15)\n",
    "ax2.imshow(plotted, cmap='gray')\n",
    "ax2.set_title('Detect lane lines', fontsize=15)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "plt.savefig(\"images/detect_lanes.png\",bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine the curvature of the lane and vehicle position with respect to center."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "center_curve = getLL.determine_curvature(target_image)\n",
    "print(\"center_curve:{:.2f}\".format(center_curve))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_position = getLL.get_vehicle_position()\n",
    "print(v_position)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warp the detected lane boundaries back onto the original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invimg = get_perspective_transformed_image(plotted, inv=1)\n",
    "ans = cv2.addWeighted(image, 1, invimg, 1, 0)\n",
    "\n",
    "f, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20, 12))\n",
    "f.tight_layout()\n",
    "ax1.imshow(plotted, cmap='gray')\n",
    "ax1.set_title('Detected lane lines', fontsize=15)\n",
    "ax2.imshow(invimg, cmap='gray')\n",
    "ax2.set_title('Unwarped', fontsize=15)\n",
    "\n",
    "ax3.imshow(ans, cmap='gray')\n",
    "ax3.set_title('Detected on original image', fontsize=15)\n",
    "\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "plt.savefig(\"images/unwarped_lanes.png\",bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on Video\n",
    "Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from datetime import datetime\n",
    "import AdvLaneLine\n",
    "import importlib\n",
    "importlib.reload(AdvLaneLine)\n",
    "\n",
    "objpoints, imgpoints = get_calibration_parameters()\n",
    "AdvLL = AdvLaneLine.getLaneLine()\n",
    "\n",
    "def pipeline(image, objpoints=objpoints, imgpoints=imgpoints, AdvLaneLine=AdvLaneLine):\n",
    "    undistorted = get_undistorted_image(image, objpoints, imgpoints)\n",
    "    warped = get_perspective_transformed_image(undistorted)\n",
    "    binarized = get_binary_image(warped)\n",
    "    shadow = get_removed_shadow_binary_image(warped)\n",
    "    \n",
    "    # Remove side of warped image to prevent misrecognition\n",
    "    #binarized[:, 0:150] = 0\n",
    "    #binarized[:, 1150:] = 0\n",
    "    \n",
    "    # Remove shadow\n",
    "    binarized[(shadow == 0)] = 0\n",
    "    \n",
    "    AdvLL.sliding_window_search(binarized, margin=70)\n",
    "\n",
    "    detected = AdvLL.get_plotted_lane_lines_binalized_image(binarized)\n",
    "    \n",
    "    center_curve = AdvLL.determine_curvature(detected)\n",
    "    vehicle_position = AdvLL.get_vehicle_position()\n",
    "    \n",
    "    # Warp the detected lane boundaries back onto the original image\n",
    "    unwarped = get_perspective_transformed_image(detected, inv=1)\n",
    "    result = cv2.addWeighted(image, 1, unwarped, 1, 0)\n",
    "\n",
    "    center_curve_text = \"Radius of curvature = {:.2f}(m)\".format(center_curve)\n",
    "\n",
    "    if vehicle_position >= 0:\n",
    "        vehicle_position_text = \"Vehicle is {:.2f}m left of center\".format(abs(vehicle_position))\n",
    "    else:\n",
    "        vehicle_position_text = \"Vehicle is {:.2f}m right of center\".format(abs(vehicle_position))\n",
    "    \n",
    "    cv2.putText(result, center_curve_text, (20,50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255),3, cv2.LINE_AA)\n",
    "    cv2.putText(result, vehicle_position_text, (20,100), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255),3, cv2.LINE_AA)\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    f, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(20, 12))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(image)\n",
    "    ax1.set_title('Original Image', fontsize=10)\n",
    "    ax2.imshow(warped)\n",
    "    ax2.set_title('Warped Image', fontsize=10)\n",
    "    ax3.imshow(binarized, cmap='gray')\n",
    "    ax3.set_title('Binarized Image', fontsize=10)\n",
    "    ax4.imshow(result, cmap='gray')\n",
    "    ax4.set_title('Detect Lane Lines', fontsize=10)\n",
    "    \n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "    \n",
    "    #plt.imshow(result)\n",
    "    plt.savefig(\"output_images/result3/result_{}.png\".format(datetime.now().isoformat()), bbox_inches=\"tight\")\n",
    "    \"\"\"\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = mpimg.imread('test_images/test2.jpg')\n",
    "show_processed_images(image, pipeline(image))\n",
    "plt.savefig(\"result_test2.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "white_output = 'result_project_video.mp4'\n",
    "clip1 = VideoFileClip('project_video.mp4')\n",
    "white_clip = clip1.fl_image(pipeline)\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SDCpy35",
   "language": "python",
   "name": "sdcpy35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 1,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
